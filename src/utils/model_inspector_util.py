# (((((((((((((##########%%%#((((((((((((((((((((((((((((((((((((((((##%%%%%%%%%%###%#/,.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
# (((((((((((((((((##########%%%##(((((((((((((((((((((((((((((##%%%%%%%%%%####(*,........,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
# (((((((((((((((((((((((#########%%%%&&&&%#(((((((((##%&&&&&&%%%%%%##%##/,,,..,...,,,.......,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
# ((((((((((((((((((((((((((((#&@#((/((((((((((((((((((((((((((((#@%...,,,,...................,,,,,,,,,,,,,,,,,,,,,,,,,,,,
# (((((((((((((((((((((((((%@(((((((((((((((((((((((((((((((((((((((((#&&*...................,..,,,,,,,,,,,,,,,,,,,,,,,,,,
# ((((((((((((((((((((#((&#((((((((((((((((((((((((((((((((((((((((((((((((%&/..,.,...............,,,,,,,,,,,,,,,,,,,,,,,,
# %%%#(((((((((((((((((&(((((((((((((((((((((((((((((((((((((((((((((((((((((((&#,...,.............,,,,,,,,,,,,,,,,,,,,,,,
# ####%%###((((((((((%%((((((((((((((((((((((((((/((((((((((((((((((((((((((((((((%#,..,,........,...,,,,,,,,,,,,,,,,,,,,,
# ((#######%%%##(((#&#((((((((((((((((((((((((/((//((((((((((((((((((((((((((((((((((&/................,,,,,,,,,,,,,,,,,,,
# ((((((#####%%%%%%&#((((((((((((((((((((((##//*///(%((((((((((((((((((((((((((((((((((%%////*.....,....,,,,,,,,,,,,,,,,,,
# ((((##%%%%%%%%%%&%((((((((((((((((((((((#///%(*////*#((((((((#(((((((((((((((((((((((((#%(((((%&*.,..,..,,,,,,,,,,,,,,,,
# %%%%%%##%#(/,.,.%((((((((((((((((((((((#*/((#&(//*/*/%(((((((/(%#(((((((((((((((((((((((((%(((((%(.,......,,,,,,,,,,,,,,
# %%##/....,,....,%((((((((((((((((((((((%**/AISHIELD*/#((((((((((/(%#(((((((((((((((((((((((((((((&.,.......,,,,,,,,,,,,,
# ................/&((((((((((&(/(((((((((#(*/(((/(**(#(((((((((((((((((%#((((((((((((((((((((((((&*.,,........,,,,,,,,,,,
# ................./#(((((((((/%((((((((((/(((#%%%##(((((((((((((((((((((((((%%#/(((((((((((((((&(..,..........,,,,,,,,,,,
# ................,.*@((((((((((%(((((((((((((((((((((((((#######%%#####((((((((((((###%%#&%(*,.....,.........,...,,,,,,,,
# ..................,.,&%((((((((#(((((((/((#%&&&&&&&%%%&&&&&&&&&&&&%%%&%&%&%%%%%%%&&&&&&%%@,..,.................,..,,,,,,
# .................,,....,,/#&&%#%%((#%&&%&%&&%%%%%%%%%%%%%%%%%%%%%%&&&&&%%%%%%%%%&&&&&%&&%&(,*,,..................,..,,,,
# .............................,,.(&%%%%%&%&%%%&&%%%%%%&&&&@&&%####(%#/%@@@%///////&@&&@@@&(**///&,,.,.................,,,
# ................................,#&%&%%&%%&&&%##((((((((((((((%&&@@&(////*/////(###&@&&%///#(///%/.....................,
# ................................,.&&%#((((((((((((((((((##&@@@%#/*/((#%(/*,&@@@(//*/#&&//#///////&,,...................,
# ................................,%((((((((((((((#%%(/////#%@@@@@@@@@@&,,.,@@@@@&*///*##//&(((////&,,................,,..
# ........,..,...,............,..(%((##&%#(/*/(%%&@@@@//////&@@@@@@@@@%.,,,@@@@@@@*/////*/////#///(#,.....................
# ......,...*@/*##...........,.,.../&@@@@@@@#.,.(@@@@@%#/////%@@@@@@@(,,.*@@@@@@@%///////**//////&*..,....................
# ...........#(///%(..,.............&@@@@@@*,..#@@@@@@//////*//%@@@@*,,.,@@@@@@@@///////#&%%#%%(,.........................
# .......,.,,,,&(/*/&*.,..........,,,&@@@&,.,.(@@@@@@(////////////%/,.,/@@@@@@%/*///////#*.....,,.........................
# ......,....,..*&///(%..,............#@%,.,,#@@@@@@///*(#/*///////////*//////////*////&*......,,.........................
# .......,.,.,#(/*#//*/&,,,.........,...(%,.#@@@@&(//*//*///////////////////////////*#%,......,.,.........................
# .......,,##/((//#/*///%/...............,&///**///////////(@&&&#///////////////*//##/////#((%&(,,........................
# .......,%##/#%((##%(((/((.,..........,.,,&(*///*//////////&&@%&//////////////*/%((((//((%/(((/((%%/,..,.................
# ......,(%//#(*//////////(%....,...........,#&(/////////////(#///////////*/*(%(((((((//(#((((((((((%((&#,.,,.............
# ........,&%/%/*/#/*///*//((,..............,.,,*&&(///////////*/*///////#&#(/((((((((/*(##(((((((##((%///*%%,.,..........
# ..........,&(/////#/*//////&,.,........,,...#&#((/((((#&#(//*//**(&#((/(/#((((((((/((*/(%((((//(#((#/////////&/...,,....
# ............,(%/*////*///////%*........./&#((((%(((((((%((((((##*#(((((##&((((((((((((*(#%(((((&((#///////*/*///#%,.,...
# ...........,,..,&/////////////*%(...,(&###((((((%((((((%((((##%#(%((@&((((//////((%%(((*/(%*%&%((((/*//////////////#%,..
# ................,,%*/////////*//*#@%//(#((##(((((%/(((((((/(((((((%/(((((/,*/((#%&%#%(((//%/,,.,#&(///////////////////&/
# .................,.*%////////*//*///%//*/#((#(((((%((((((((#%@%(,%(%(((((%((((((((%#(#((//(#.,,.,,,./&(/////////////////
# ................,.,..*&//////////////////*(#((%(&/,@(((&(%###&%#(#(#((((((#/*/(##((/(&(*/((&.,........,./&////*/////////
# .....................,.*&///////////**///*//%&/,,..,(%((#/(((((##(##%(((((#((/*//((/*/#((/(&,........,,.,..##*//////////
# ......................,.,,&(/////////////(&*...,.....,&((%(((((((((#(##&&((#(((##%%#(((((((%/................/%/////////
# .......................,..,,#%*///////(&,.,..........,.##(#(((((((((%##(/((((((((((((((((((##.................,,&///////
# ............................,,(%///%&,...............,../&(&%%((((((((%(((((((((((((((((((((#,..................,,&////*
# ............................,.,.,/,,.,....,............,,,&((((((((((((#((((((((((((((((((((&,.....................,@//*

__author__ = "AIShield"
__copyright__ = "Copyright @2023 Bosch Global Software Technologies Private Limited."
__credits__ = "AIShield"
__license__ = "Apache-2.0"
__version__ = "1.0"
__maintainer__ = "AIShield"
__email__ = "AIShield.Contact@bosch.com"
__status__ = "Beta"

# import libraries
import os
import h5py
import base64
import inspect
import zipfile
import json

from picklescan import scanner
import torch
import torch.nn as nn
from safetensors import safe_open

# load external files for safe model load (.h5, .pb, .keras)
from external_files import model_safe_load

# list of keras official layers (From Tensorflow 2.16.1)
keras_layers_tf_2_16_1 = ['Activation',
                          'ActivityRegularization',
                          'Add',
                          'AdditiveAttention',
                          'AlphaDropout',
                          'Attention',
                          'AutoContrast',
                          'Average',
                          'AveragePooling1D',
                          'AveragePooling2D',
                          'AveragePooling3D',
                          'AvgPool1D',
                          'AvgPool2D',
                          'AvgPool3D',
                          'BatchNormalization',
                          'Bidirectional',
                          'CategoryEncoding',
                          'CenterCrop',
                          'Concatenate',
                          'Conv1D',
                          'Conv1DTranspose',
                          'Conv2D',
                          'Conv2DTranspose',
                          'Conv3D',
                          'Conv3DTranspose',
                          'ConvLSTM1D',
                          'ConvLSTM2D',
                          'ConvLSTM3D',
                          'Convolution1D',
                          'Convolution1DTranspose',
                          'Convolution2D',
                          'Convolution2DTranspose',
                          'Convolution3D',
                          'Convolution3DTranspose',
                          'Cropping1D',
                          'Cropping2D',
                          'Cropping3D',
                          'Dense',
                          'DepthwiseConv1D',
                          'DepthwiseConv2D',
                          'Discretization',
                          'Dot',
                          'Dropout',
                          'ELU',
                          'EinsumDense',
                          'Embedding',
                          'Flatten',
                          'FlaxLayer',
                          'GRU',
                          'GRUCell',
                          'GaussianDropout',
                          'GaussianNoise',
                          'GlobalAveragePooling1D',
                          'GlobalAveragePooling2D',
                          'GlobalAveragePooling3D',
                          'GlobalAvgPool1D',
                          'GlobalAvgPool2D',
                          'GlobalAvgPool3D',
                          'GlobalMaxPool1D',
                          'GlobalMaxPool2D',
                          'GlobalMaxPool3D',
                          'GlobalMaxPooling1D',
                          'GlobalMaxPooling2D',
                          'GlobalMaxPooling3D',
                          'GroupNormalization',
                          'GroupQueryAttention',
                          'HashedCrossing',
                          'Hashing',
                          'Identity',
                          'Input',
                          'InputLayer',
                          'InputSpec',
                          'IntegerLookup',
                          'JaxLayer',
                          'LSTM',
                          'LSTMCell',
                          'Lambda',
                          'Layer',
                          'LayerNormalization',
                          'LeakyReLU',
                          'Masking',
                          'MaxPool1D',
                          'MaxPool2D',
                          'MaxPool3D',
                          'MaxPooling1D',
                          'MaxPooling2D',
                          'MaxPooling3D',
                          'Maximum',
                          'MelSpectrogram',
                          'Minimum',
                          'MultiHeadAttention',
                          'Multiply',
                          'Normalization',
                          'PReLU',
                          'Permute',
                          'Pipeline',
                          'RNN',
                          'RandomBrightness',
                          'RandomContrast',
                          'RandomCrop',
                          'RandomFlip',
                          'RandomHeight',
                          'RandomRotation',
                          'RandomTranslation',
                          'RandomWidth',
                          'RandomZoom',
                          'ReLU',
                          'RepeatVector',
                          'Rescaling',
                          'Reshape',
                          'Resizing',
                          'SeparableConv1D',
                          'SeparableConv2D',
                          'SeparableConvolution1D',
                          'SeparableConvolution2D',
                          'SimpleRNN',
                          'SimpleRNNCell',
                          'Softmax',
                          'Solarization',
                          'SpatialDropout1D',
                          'SpatialDropout2D',
                          'SpatialDropout3D',
                          'SpectralNormalization',
                          'StackedRNNCells',
                          'StringLookup',
                          'Subtract',
                          'TFSMLayer',
                          'TextVectorization',
                          'ThresholdedReLU',
                          'TimeDistributed',
                          'TorchModuleWrapper',
                          'UnitNormalization',
                          'UpSampling1D',
                          'UpSampling2D',
                          'UpSampling3D',
                          'Wrapper',
                          'ZeroPadding1D',
                          'ZeroPadding2D',
                          'ZeroPadding3D',
                          '__builtins__',
                          '__cached__',
                          '__doc__',
                          '__file__',
                          '__loader__',
                          '__name__',
                          '__package__',
                          '__path__',
                          '__spec__',
                          'add',
                          'average',
                          'concatenate',
                          'deserialize',
                          'dot',
                          'maximum',
                          'minimum',
                          'multiply',
                          'serialize',
                          'subtract']


def contains_pickled_data_direct_scan(h5_file_path: str):
    """
        Directly scan an .h5 file for the presence of pickled data patterns.

        This function checks an HDF5 file for the existence of pickled data patterns, which can indicate
        potential security vulnerabilities. Pickled data is a serialization format in Python that can
        execute arbitrary code when deserialized.

        Parameters:
            h5_file_path (str): The path to the HDF5 file to be scanned for pickled data patterns.

        Returns:
            bool: True if pickled data patterns are detected in the file, indicating a potential
                  security issue; False otherwise.

        Note:
        - The function searches for specific "magic numbers" used in Pickle serialization to identify
          potential pickled data.
        - It also checks for certain "opcodes" that can indicate pickling operations within the file.
        - If pickled data patterns are found, the function prints a message and sets the status to True.
          Otherwise, it returns False.

    """

    status = False
    # Pickle's magic numbers for various protocols
    pickle_magic_numbers = [b'\x80\x03', b'\x80\x04', b'\x80\x05']

    # Pickle opcodes that can indicate pickling operations
    suspicious_opcodes = [b'c', b'g', b'(', b'.', b'0']

    try:
        with open(h5_file_path, 'rb') as f:
            file_content = f.read()
            for magic in pickle_magic_numbers:
                if magic in file_content:
                    # Check for subsequent suspicious opcodes
                    index = file_content.find(magic)
                    subsequent_data = file_content[index:index + 10]  # Check next 10 bytes
                    if any(op in subsequent_data for op in suspicious_opcodes):
                        print(f"Detected pickle pattern after magic number: {magic}")
                        status = True

    except Exception as e:
        print("Scanning any pickled Data scan from the model: {}".format(str(e)))

    return status


def unsafe_check_pkl(model_path: str):
    """
    The unsafe_check_pkl function is designed to analyze models with the .pkl extension for potential
    vulnerabilities. If any vulnerabilities are detected, it will provide information about the vulnerability along
    with a severity rating. The severity rating for .pkl files is considered as Medium because Pickle files have the
    potential to execute arbitrary code and involve serialization, which can introduce security risks.

    Parameters:
        - model_path (str): The path to the model file (.pkl) that you want to scan for vulnerabilities.

    Returns: - tool_output (List[str]): A list of vulnerabilities found during the pickle model scanning process. If
    no vulnerabilities are found, an empty list will be returned.

    """
    tool_output = list()
    if model_path.endswith('.pkl'):
        tool_output.append("pickle_file#Severity:Medium - Detected .pkl file. Pickle can execute arbitrary code.")
        print("Detected .pkl file. -Pickle can execute arbitrary code.")

    return tool_output


def unsafe_check_h5(model_path: str):
    """
        The unsafe_check_h5 function is designed to inspect models with the .h5 extension for potential vulnerabilities.
        If any vulnerabilities are detected, it will provide information about the vulnerability along with a severity
        rating. The severity rating helps users understand the potential risk associated with each vulnerability.
        Vulnerability Severity Ratings:
        - High Severity: Pickle/magic numbers detected.
                Reason: Pickle can execute arbitrary code.
        - High Severity: Lambda layer found.
                Reason: Lambda layers can execute arbitrary code.
        - Medium Severity: Non-Keras layer found.
               Reason: Non-Keras custom layers may contain arbitrary code but require explicit loading.
        - Medium Severity: Unknown layer found.
                Reason: The model contains an unknown custom layer, which requires explicit loading.
        - Low Severity: Unable to load the model.
            Reason: The model cannot be loaded, potentially indicating an issue.
       
        Parameters:
            - model_path (str): The path to the model file (.h5) that you want to scan for vulnerabilities.
 
        Returns:
            - tool_output (List[str]): A list of vulnerabilities found during the pickle model scanning process.
                                      If no vulnerabilities are found, an empty list will be returned.
                                       
        """
    tool_output = list()
    lambda_layer_detected = None
    lambda_suspicious_detected = False
    moderate_lamda_suspicious_detected = False
    unsafe_layer_detected = False

    try:

        # Check for suspicious patterns in Lambda layers
        suspicious_patterns = [
            "execute_command", "os.system", "ossystem", "system", "subprocess.run", "subprocess.Popen",
            "open(", "eval(", "exec(", "import os", "import subprocess", "pickle.load", "pickle.loads", "joblib.load"
        ]
        moderate_suspicious_patterns = ["numpy.load"]

        # Replaced with safe load functions
        h5_layers, unsafe_h5_layers = model_safe_load.safe_load_model_h5_format(model_path)

        if (unsafe_h5_layers):  #list is not empty
            unsafe_layer_detected = True

        # Check for pickled data in the .h5 file
        magic_number_detected_status = contains_pickled_data_direct_scan(model_path)

        # non_keras_layer_detected = any(not hasattr(keras.layers, type(layer).__name__) for layer in model.layers)
        non_keras_layer_detected = not any(layer in keras_layers_tf_2_16_1 for layer in h5_layers)

        # If magic numbers are detected OR a suspicious Lambda layer is detected OR a non-Keras layer is detected,
        # flag the file
        if magic_number_detected_status:
            tool_output.append("magic_number_detected#Severity:High - Potential security concern detected "
                               "in the model. Pickle can execute arbitrary code")

        elif unsafe_layer_detected:
            tool_output.append("lambda_suspicious#Severity:High - Potential security concern detected "
                               "in the model, unsafe layers such as Lambda or Custom can execute arbitrary code")
            print(
                "\nPotential security concern detected in the model.Lambda layers can execute "
                "arbitrary code.")

        elif non_keras_layer_detected:
            tool_output.append("non_keras_layer#Severity:Low - Potential security concern detected "
                               "in the model. Non-Keras layers can contain arbitrary "
                               "code but require explicit loading.")
            print(
                "\nPotential security concern detected in the model, Non-Keras custom layers can contain arbitrary "
                "code but require explicit loading.")

    except ValueError as e:
        if "Unknown layer" in str(e):
            tool_output.append("Unknown layer#Severity:Medium - Potential security concern detected "
                               "in the model. Model contains an unknown custom layer."
                               "Requires explicit loading")
            print(
                "Model contains an unknown custom layer. This can be a potential security risk"
                "Requires explicit loading.")

    except Exception as e:
        tool_output.append("Error loading model#Severity:Low - Unable to load the Model {}".format(str(e)))
        print("Error loading model: {}".format(str(e)))

    return tool_output


# Function to scan a model and return a JSON report
def unsafe_check_pb(model_path: str):
    """
        The unsafe_check_pb function is designed to examine models with the .pb extension for potential vulnerabilities.
        If any vulnerabilities are detected, it will provide information about the vulnerability along with a severity
        rating.

        Vulnerability Severity Ratings:

        - High Severity: Lambda or custom layer found.
                Reason: Lambda and Custom layers in TensorFlow allow for
                        arbitrary operations. If an attacker can modify or introduce a lambda function within
                         a saved model,they can potentially execute any operation when the model is loaded.

        Parameters:
            - model_path (str): The path to the model file (.pb) that you want to scan for vulnerabilities.

        Returns:
            - tool_output (List[str]): A list of vulnerabilities found during the .pb model scanning process. If
        no vulnerabilities are found, an empty list will be returned.

        """

    tool_output = list()
    model_safe_load.safe_load_model_pb_format(model_path)

    try:
        tool_output = model_safe_load.safe_load_model_pb_format(model_path)

    except Exception as e:
        print("Failed to perform safe_load_model_pb_format due to: {}".format(str(e)))
        tool_output.append("Error loading model#Severity:Low - Unable to load the Model {}".format(str(e)))

    return tool_output


# SafeTensor Check
def unsafe_check_safetensors(model_path: str):
    """
    The unsafe_check_safetensors function is designed to examine safetensors models converted from base pytorch
    models with the .safetensors extension for potential vulnerabilities. If any vulnerabilities are detected,
    it will provide information about the vulnerability along with a severity rating.

        Vulnerability Severity Ratings:

        - High Severity: Lambda or embedded layer found.
                Reason: Lambda and Embedding layers allow for
                        arbitrary operations. If an attacker can modify or introduce a lambda function within
                         a saved model,they can potentially execute any operation when the model is loaded.
        - Medium Severity: Non-standard layer found.
                Reason: Non-standard layers, as defined by the unsafe_check_safetensors tool, include layers like 'InputLayer,
                        ' 'Dense,' 'Activation,' and others. These custom layers or operations, which are not part of
                        the standard Pytorch library, hence can cause vulnerabilities when it is converted to safetensors
                        format can introduce vulnerabilities. However, it's important to note
                        that these custom operations typically require explicit loading, meaning there's an additional
                        step before potential execution.

        Parameters:
            - model_path (str): The path to the model file (.safetensors) that you want to scan for vulnerabilities.

        Returns:
            - tool_output (List[str]): A list of vulnerabilities found during the .safetensors model scanning process.
            If no vulnerabilities are found, an empty list will be returned.

        """

    tool_output = list()
    model_layers = list()  # Create a list to append all the layers of the safetensors model

    # List of suspicious patterns to detect
    suspicious_patterns = [
        "execute_command", "os.system", "subprocess.run", "subprocess.Popen",
        "open", "eval", "exec", "import os", "import subprocess", "pickle.load", "pickle.loads", "joblib.load"
    ]
    moderate_suspicious_patterns = ["numpy.load"]

    try:
        # Load the model from the SafeTensors file
        with safe_open(model_path,
                       framework="pt") as f:  # Since the base model is a pytorch model, specifying the framework as pt
            layer_names = f.keys()
            model_layers.extend(layer_names)
    except Exception as e:
        print(f"Error loading model: {e}")
        tool_output.append("Error loading model#Severity:Low - Unable to load the Model {}".format(str(e)))
        return tool_output

    # List of standard Pytorch base safetensor layers
    standard_layers = [
        'linear', 'conv2d', 'batchnorm2d', 'relu', 'maxpool2d', 'avgpool2d',
        'adaptiveavgpool2d', 'adaptivemaxpool2d', 'dropout', 'flatten', 'rnn',
        'lstm', 'gru', 'embedding', 'layernorm',
        'InstanceNorm2d', 'GroupNorm', 'LocalResponseNorm',
        'GlobalAvgPool2d', 'GlobalMaxPool2d',
        'sigmoid', 'tanh', 'softmax',
        'transformer', 'attention', 'upsample',
        'identity', 'concat', 'reshape',
        'gaussiannoise', 'alphadropout', 'threshold'
    ]
    # Define a list of suspicious layers
    suspicious_layers = ['Lambda', "CustomLayer"]
    lamda_suspicious_layer = False
    non_standard_layer = False
    high_suspicious_pattern = False
    moderate_suspicious_pattern = False
    try:
        for layer in model_layers:
            layer_name = layer.split('.')[-2]  # Get the actual layer name

            if any(layer_name == suspicious_layer for suspicious_layer in suspicious_layers):
                lamda_suspicious_layer = True
                break
            elif any(layer_name not in standard_layers for layer_name in layer.split('.')):
                non_standard_layer = True

        for pattern in suspicious_patterns:
            if any(pattern in layer for layer in model_layers):
                high_suspicious_pattern = True
                break

        for pattern in moderate_suspicious_patterns:
            if any(pattern in layer for layer in model_layers):
                moderate_suspicious_pattern = True

        if lamda_suspicious_layer or high_suspicious_pattern:
            tool_output.append("Lamda_or_Embedding_layer#Severity:High - Detected Lambda operations in the "
                               ".safetensors model or Detected suspicious pattern  in the .safetensors model. "
                               "Reason: Lambda/ Custom layers in SafeTensors models allow for arbitrary "
                               "operations  or if suspicious pattern found that may indicate an attempt to execute arbitrary code when the "
                               " model is loaded. If an "
                               "attacker can modify or introduce a lambda function within the model, they can "
                               "potentially execute any operation when the model is loaded."
                               )
        elif moderate_suspicious_pattern or non_standard_layer:
            tool_output.append("Non_Standard_layer#Severity:Medium - Detected non-standard layers in the "
                               ".safetensors model or detected moderate suspicious pattern  in the "
                               ".safetensors model. ."
                               "Reason: Custom layers or operations that are not part of the standard SafeTensors Model "
                               "can introduce vulnerabilities. However, these custom operations typically "
                               " require explicit loading, which means there's an additional step before potential "
                               "execution. or any suspicious pattern may indicate to attempt to load the arbitrary data when the model is loaded")

    except Exception as e:
        print("Failed to Perform unsafe-check-safetensors due to: {}".format(str(e)))

    return tool_output


def scan_pickle_file(path: str):
    """
    This function takes pickle file path as input to scan for static vulnerability in pickle file
    
    severity mapping as below. only 3 format the safety is given by scanner
    Low = "innocuous"
    Medium = "suspicious"
    High = "dangerous"

    Parameters
    ----------
    path : str
        DESCRIPTION. full path of file

    Returns
    -------
    None.

    """
    results = []
    pickle_scan_result = scanner.scan_file_path(path=path)
    for pickle_vulnerability in pickle_scan_result.globals:
        module = pickle_vulnerability.module
        name = pickle_vulnerability.name
        safety = pickle_vulnerability.safety.value
        severity = "High" if safety == 'dangerous' else "Medium" if safety == 'suspicious' else "Low"
        results.append({'module': module, "name": name, "severity": severity})

    # Other variable of scanner class
    # pickle_scan_result.scanned_files
    # pickle_scan_result.issues_count
    # pickle_scan_result.infected_files
    # pickle_scan_result.scan_err

    return results
# %%
